{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c6171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Great set of questions about **Random Forest Regressor**! Let’s go through them one by one:\n",
    "\n",
    "---\n",
    "\n",
    "### **Q1. What is Random Forest Regressor?**\n",
    "\n",
    "**Random Forest Regressor** is an **ensemble learning algorithm** that:\n",
    "- Builds multiple **decision trees** on different subsets of the data.\n",
    "- Aggregates their predictions by **averaging** for regression tasks.\n",
    "- Is a **bagging technique** that reduces overfitting and improves accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q2. How does Random Forest Regressor reduce the risk of overfitting?**\n",
    "\n",
    "It reduces overfitting by:\n",
    "- Using **bootstrapped samples** of the training data (sampling with replacement).\n",
    "- At each split, choosing from a **random subset of features**.\n",
    "- Averaging predictions from multiple trees, which **smooths out individual tree noise**.\n",
    "\n",
    "This ensures **diversity** among trees and leads to a **lower variance model**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?**\n",
    "\n",
    "For regression:\n",
    "- Each decision tree outputs a **numeric prediction**.\n",
    "- The Random Forest **averages** all tree predictions to produce the final output.\n",
    "\n",
    "\\[\n",
    "\\hat{y} = \\frac{1}{T} \\sum_{i=1}^T \\hat{y}_i\n",
    "\\]  \n",
    "where \\( \\hat{y}_i \\) is the prediction from tree \\(i\\), and \\(T\\) is the number of trees.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q4. What are the hyperparameters of Random Forest Regressor?**\n",
    "\n",
    "Key hyperparameters in `RandomForestRegressor` (from `sklearn.ensemble`) include:\n",
    "\n",
    "| Hyperparameter            | Description |\n",
    "|---------------------------|-------------|\n",
    "| `n_estimators`            | Number of trees in the forest |\n",
    "| `max_depth`               | Maximum depth of each tree |\n",
    "| `min_samples_split`       | Minimum samples required to split a node |\n",
    "| `min_samples_leaf`        | Minimum samples required at a leaf node |\n",
    "| `max_features`            | Number of features to consider at each split |\n",
    "| `bootstrap`               | Whether bootstrap samples are used |\n",
    "| `random_state`            | Seed for reproducibility |\n",
    "\n",
    "---\n",
    "\n",
    "### **Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?**\n",
    "\n",
    "| Feature                        | Decision Tree Regressor      | Random Forest Regressor        |\n",
    "|-------------------------------|------------------------------|--------------------------------|\n",
    "| **Model Type**                | Single tree                  | Ensemble of multiple trees     |\n",
    "| **Overfitting**               | High risk                    | Less prone due to averaging    |\n",
    "| **Prediction**                | From one tree                | Average of many trees          |\n",
    "| **Variance**                  | High                         | Lower                          |\n",
    "| **Interpretability**          | Easy                         | Harder                         |\n",
    "| **Accuracy (typically)**      | Lower                        | Higher                         |\n",
    "\n",
    "---\n",
    "\n",
    "### **Q6. What are the advantages and disadvantages of Random Forest Regressor?**\n",
    "\n",
    "- Handles **non-linearity** well\n",
    "- **Reduces overfitting**\n",
    "- Works well with **missing values** and **outliers**\n",
    "- Requires **little preprocessing**\n",
    "\n",
    "- **Less interpretable** than a single tree\n",
    "- **More computationally expensive**\n",
    "- Not ideal for **real-time predictions** (large model size)\n",
    "\n",
    "---\n",
    "\n",
    "### **Q7. What is the output of Random Forest Regressor?**\n",
    "\n",
    "- It outputs a **continuous numeric value** (a regression prediction).\n",
    "- This value is the **average prediction** of all the decision trees in the forest.\n",
    "\n",
    "---\n",
    "\n",
    "### **Q8. Can Random Forest Regressor be used for classification tasks?**\n",
    "\n",
    "- Not directly, but there is a closely related model: **`RandomForestClassifier`**.\n",
    "- Both use the same principles—bagging + decision trees—but:\n",
    "  - `RandomForestRegressor` → **averages predictions**\n",
    "  - `RandomForestClassifier` → **uses majority voting**\n",
    "\n",
    "So yes, **Random Forests** can be used for classification—but you need to use the **classifier version** of the algorithm.\n",
    "\n",
    "---\n",
    "\n",
    "Want to see a code example with `RandomForestRegressor` in action on a real dataset like Boston housing or California housing?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
